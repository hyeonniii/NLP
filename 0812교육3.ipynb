{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0812교육3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8VLzKNS5THX+NeK8dMvmb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonniii/NLP/blob/main/0812%EA%B5%90%EC%9C%A13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pURzjkR5bXSy",
        "outputId": "9827f72e-876e-4032-8e1b-d8567095bb47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['국책연구기관', '딥러닝', '기본과정입니다']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "text = \"국책연구기관 딥러닝 기본과정입니다.\"\n",
        "text_to_word_sequence(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "doc = ['국책연구기관 딥러닝 기본과정입니다.','한국개발연구원 정책대학원 컴퓨터실입니다.', '딥러닝 마스터가 됩시다.']\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(doc)\n",
        "print(token.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vUGZMqOcZg_",
        "outputId": "19790c58-a3be-4582-fed8-673cccf56169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('국책연구기관', 1), ('딥러닝', 2), ('기본과정입니다', 1), ('한국개발연구원', 1), ('정책대학원', 1), ('컴퓨터실입니다', 1), ('마스터가', 1), ('됩시다', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네이버 영화 리뷰 데이터를 활용한 영화 감성분석 예제\n"
      ],
      "metadata": {
        "id": "19IboASfdq6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "Dx9ABn9Yd0IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최신 버전의 사이킷런을 설치 및 확인\n",
        "!pip install --upgrade scikit-learn\n",
        "# 한국형 형태소 분석(표제어 추출 방식)을 위한 패키지 'konlpy'를 설치\n",
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWcXEjJVdz5f",
        "outputId": "d4f2b930-7eaf-4f45-c150-4bc90760042b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "필요한 함수 불러오기:\n",
        "konlpy - (\"코엔엘파이\"라고 읽습니다)는 한국어 정보처리를 위한 파이썬 패키지 입니다 \n",
        "(https://konlpy.org/ko/v0.5.2/)\n",
        "konlpy는 한국어 형태소 분석기 패키지 입니다\n",
        "\"\"\"\n",
        "\n",
        "import konlpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "wARQVF4ndjgg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- 깃허브에 있는 데이터를 빌려(?) 오기\n",
        "- 데이터는 IMDb의 영화 리뷰 데이터셋과 비슷한 네이버 영화 리뷰 데이터셋(https://github.com/e9t/nsmc)을 활용하였습니다\n",
        "- 약 20만건의 영화 리뷰를 2015년을 기준으로 수집한 데이터 입니다.\n",
        "- \"머신러닝 교과서 with 파이썬, 사이킷런, 텐서프로 (개정3판)\"에서 해당 데이터를 따로 제공하고 있으므로, 해당 깃허브를 통해서 간단히 내려받기 합니다\n",
        "\"\"\"\n",
        "\n",
        "# Training (훈련) 데이터 받기\n",
        "!wget https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch08/ratings_train.txt -O ratings_train.txt\n",
        "\n",
        "# Testing (테스트) 데이터 받기\n",
        "!wget https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch08/ratings_test.txt -O ratings_test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxcNbeRJenFm",
        "outputId": "19d09ebc-37f4-4984-a78b-ab92dcaa4f9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-12 05:17:42--  https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch08/ratings_train.txt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch08/ratings_train.txt [following]\n",
            "--2022-08-12 05:17:42--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch08/ratings_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [text/plain]\n",
            "Saving to: ‘ratings_train.txt’\n",
            "\n",
            "ratings_train.txt   100%[===================>]  13.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-08-12 05:17:42 (125 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
            "\n",
            "--2022-08-12 05:17:42--  https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch08/ratings_test.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch08/ratings_test.txt [following]\n",
            "--2022-08-12 05:17:42--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch08/ratings_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [text/plain]\n",
            "Saving to: ‘ratings_test.txt’\n",
            "\n",
            "ratings_test.txt    100%[===================>]   4.67M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-08-12 05:17:42 (62.2 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing\n"
      ],
      "metadata": {
        "id": "cJp-eUe7fSwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 내려받기 된 데이터를 읽어볼까요?\n",
        "\"\"\"\n",
        "(부록 F 참조)\n",
        "+-----------------------+\n",
        "|     Training Set     |  <--- 약 75%\n",
        "+-----------------------+\n",
        "|      Testing Set     |  <--- 약 25%\n",
        "+-----------------------+\n",
        "\n",
        "\"\"\"\n",
        "# Training Data\n",
        "Review_train = pd.read_csv('ratings_train.txt', \n",
        "                       delimiter='\\t', keep_default_na=False)\n",
        "\n",
        "# Testing Data\n",
        "Review_test = pd.read_csv('ratings_test.txt', \n",
        "                      delimiter='\\t', keep_default_na=False)\n",
        "\n",
        "# 데이터의 첫 5줄 정도 빠르게 보기를 통한 내용 파악\n",
        "# document 컬럼은 리뷰내용을, label은 긍정(1)과 부정(0)을 나타내고 있습니다\n",
        "# training data 확인\n",
        "\n",
        "Review_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2Vxu__9mfUfG",
        "outputId": "5f49f687-a99a-4eca-87f9-859d8326abcd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4eca80f-b83c-4808-bb0b-9cd9959720d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4eca80f-b83c-4808-bb0b-9cd9959720d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4eca80f-b83c-4808-bb0b-9cd9959720d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4eca80f-b83c-4808-bb0b-9cd9959720d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ycanns/DeepLearning_Class_NRC/blob/f6b7102641d4580ec788f29157eff410a681042e/data/naver_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u53X5P7RfdHX",
        "outputId": "37e30bc0-fc12-4f1f-b5eb-596faf5b540a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-12 05:37:00--  https://github.com/ycanns/DeepLearning_Class_NRC/blob/f6b7102641d4580ec788f29157eff410a681042e/data/naver_data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘naver_data.zip’\n",
            "\n",
            "naver_data.zip          [ <=>                ] 139.74K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-08-12 05:37:00 (1.79 MB/s) - ‘naver_data.zip’ saved [143094]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/naver_data.zip\" -d \"/content/naver_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYMbDuKgjnkt",
        "outputId": "125fa5c1-457a-4a47-a2e1-3b3db9f8d575"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/naver_data.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/naver_data.zip or\n",
            "        /content/naver_data.zip.zip, and cannot find /content/naver_data.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 그룹(document, 리뷰내용)과 타겟데이터 그룹 (label, 긍/부정)으로 분류하여 저장\n",
        "\"\"\"\n",
        "(부록 F 참조)\n",
        "    (document)      (label)\n",
        "+----------------+-------------+\n",
        "|   Data_train   | Target_train|  <--- Training Set (Review_train)\n",
        "+------------------------------+\n",
        "|    Data_test   | Target_test |  <--- Testing Set (Review_test)\n",
        "+------------------------------+\n",
        "\n",
        "\"\"\"\n",
        "# Review_train 데이터의 훈련데이터 \n",
        "Data_train = Review_train['document'].values\n",
        "Target_train = Review_train['label'].values\n",
        "\n",
        "# Review_test 데이터의 훈련데이터 \n",
        "Data_test = Review_test['document'].values\n",
        "Target_test = Review_test['label'].values\n",
        "\n",
        "# training 데이터의 크기확인\n",
        "print(len(Data_train), np.bincount(Target_train))\n",
        "\n",
        "# testing 데이터의 크기확인\n",
        "print(len(Data_test), np.bincount(Target_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfdTLCl8mf9C",
        "outputId": "e61e5f8a-fff6-4352-c3cf-f11eb0225e5a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150000 [75173 74827]\n",
            "50000 [24827 25173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data analysis & training"
      ],
      "metadata": {
        "id": "XtGhb1Z4m84c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt() # Okt 형태소 분석기 호출\n",
        "\n",
        "# 4번째 리뷰 내용을 바탕으로 형태소분리 (morphs 행태소 추출 모듈)\n",
        "print(Data_train[4])\n",
        "print(okt.morphs(Data_train[4]))\n",
        "print(okt.nouns(Data_train[4])) # 명사추출 예시"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5YGK59Tm648",
        "outputId": "ad775b31-9bc0-45a2-a1e2-b24480980c1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
            "['사이', '몬페', '그', '의', '익살스런', '연기', '가', '돋보였던', '영화', '!', '스파이더맨', '에서', '늙어', '보이기만', '했던', '커스틴', '던스트', '가', '너무나도', '이뻐', '보였다']\n",
            "['몬페', '의', '연기', '영화', '스파이더맨', '커스틴', '던스트']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import save_npz, load_npz\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "if not os.path.isfile('okt_train.npz'):\n",
        "    \"\"\"\n",
        "    - TfidVectorzier는 기본적으로 공백을 기준으로 토큰을 구분\n",
        "    - ngram_range : N-gram에서 고려할 단어뭉치 수 (1개 유니그램, 2개 바이그램)\n",
        "    - min_df : 최소 고려 토큰 (특정 횟수이상 등장하는 토큰만을 고려)\n",
        "    - max_df : 무시할 가장 많이 등장하는 상위 백분율\n",
        "    - okt.morphs: 형태소 분석을 통한 토큰화\n",
        "    \"\"\" \n",
        "\n",
        "    tfidf = TfidfVectorizer(ngram_range=(1, 2), \n",
        "                            min_df=3,\n",
        "                            max_df=0.9,\n",
        "                            tokenizer=okt.morphs, \n",
        "                            token_pattern=None)\n",
        "    tfidf.fit(Data_train)\n",
        "    Data_train_okt = tfidf.transform(Data_train)\n",
        "    Data_test_okt = tfidf.transform(Data_test)\n",
        "    save_npz('okt_train.npz', Data_train_okt)\n",
        "    save_npz('okt_test.npz', Data_test_okt)\n",
        "else:\n",
        "    Data_train_okt = load_npz('okt_train.npz')\n",
        "    Data_test_okt = load_npz('okt_test.npz')"
      ],
      "metadata": {
        "id": "c1XtvLPLnB_F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run model"
      ],
      "metadata": {
        "id": "nXaIUKJ1nfhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라메터 최적화를 위한 분류기법 등의 모듈 불러오기\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "from sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent (SGD)\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "\n",
        "\n",
        "#- 만약, 가용한 CPU 코어의 여유가 있다면 n_jobs (병렬 처리 할 때 사용되는 CPU 코어 수)를 추가하여 설정\n",
        "sgd = SGDClassifier(loss='log', random_state=1) \n",
        "param_dist = {'alpha': loguniform(0.0001, 100.0)} # alpha : 값이 클수록 강력한 정규화(규제) 설정\n",
        "\n",
        "rsv_okt = RandomizedSearchCV(estimator=sgd,\n",
        "                             param_distributions=param_dist,\n",
        "                             n_iter=50,\n",
        "                             random_state=1,\n",
        "                             verbose=1) #0 = 아무것도 표시 않음/ 1 = 프로그래스 바 표시/ 2 = 이포크마다 표시\n",
        "rsv_okt.fit(Data_train_okt, Target_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_ISGwJnfKj",
        "outputId": "7de8da9f-5a7a-4f2b-f666-775f31e0f925"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(estimator=SGDClassifier(loss='log', random_state=1),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f96f22e2110>},\n",
              "                   random_state=1, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "mdnd0OVoogIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rsv_okt.best_score_)  # 최적의 실험결과\n",
        "print(rsv_okt.best_params_) # 최적의 파라메터 값 (alpha)\n",
        "# 테스트셋을 이용한 검증\n",
        "rsv_okt.score(Data_test_okt, Target_test)"
      ],
      "metadata": {
        "id": "YoYBycwYoiAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMDb 영화 리뷰 데이터를 이용한 감성분석 + 머신러닝 예시\n"
      ],
      "metadata": {
        "id": "v43lPypTpBmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "nOhjlVTvpG51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최신 버전의 사이킷런을 설치 및 확인\n",
        "!pip install --upgrade scikit-learn\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tarfile        # tar 형태의 압축파일 해제를 위한 모듈\n",
        "import time           # 시간 확인을 위한 모듈 (옵션)\n",
        "import urllib.request # 인터넷 주소로부터 데이터를 구득하기 위한 모듈\n",
        "\n",
        "# 데이터를 불러올 소스의 인터넷 주소와 파일명 (직접 받아도 되고.. )\n",
        "source = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "target = 'aclImdb_v1.tar.gz' # 해당 파일이름\n",
        "\n",
        "\n",
        "def reporthook(count, block_size, total_size):\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = progress_size / (1024.**2 * duration)\n",
        "    percent = count * block_size * 100. / total_size\n",
        "\n",
        "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n",
        "                    (percent, progress_size / (1024.**2), speed, duration))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "if not os.path.isdir('aclImdb') and not os.path.isfile('aclImdb_v1.tar.gz'):\n",
        "    urllib.request.urlretrieve(source, target, reporthook)\n",
        "    \n",
        "\n",
        "# Download가 완료된 tar 파일의 압축 해제\n",
        "if not os.path.isdir('aclImdb'):\n",
        "\n",
        "    with tarfile.open(target, 'r:gz') as tar:\n",
        "        tar.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dQtErmApGZz",
        "outputId": "68deffa0-3ce4-4cb2-a2db-05bafdfcfac2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "100% | 80 MB | 1.88 MB/s | 42 sec elapsed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "필요한 함수들을 불러오기: \n",
        "numpy - 복잡한 산술계산,\n",
        "padas - 데이터의 효과적인 연산을 위한 모듈\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# `basepath`를 압축 해제된 영화 리뷰 데이터셋이 있는 디렉토리로 바꿉니다\n",
        "basepath = 'aclImdb'\n",
        "\n",
        "# 폴더명을 기준으로 각 txt 파일을 읽고, 리뷰평을 추가하는 방식\n",
        "# 별점 5개는 긍정/ 5개 미만은 부정으로 기록이 되어있습니다\n",
        "\n",
        "labels = {'pos': 1, 'neg': 0}\n",
        "df = pd.DataFrame()\n",
        "for s in ('test', 'train'):\n",
        "    for l in ('pos', 'neg'):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in sorted(os.listdir(path)):\n",
        "            with open(os.path.join(path, file), \n",
        "                      'r', encoding='utf-8') as infile:\n",
        "                txt = infile.read()\n",
        "            df = df.append([[txt, labels[l]]], \n",
        "                           ignore_index=True)\n",
        "df.columns = ['review', 'sentiment']"
      ],
      "metadata": {
        "id": "ZF5LXwHdpxD7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "_F9i8CDAp1Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한데 모아진 영화 리뷰 데이터의 순서를 섞습니다.\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HUgMELaRp3bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불필요한 특수문자나 HTML 언어 등을 선별하여 정리\n",
        "import re\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text)\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text\n",
        "\n",
        "df['review'] = df['review'].apply(preprocessor)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sJfy3U7yqfoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 (약 75%) 데이터와 테스트 (약 25%) 데이터로 나누어 저장\n",
        "X_train = df.loc[:37500, 'review'].values\n",
        "y_train = df.loc[:37500, 'sentiment'].values\n",
        "X_test = df.loc[17500:, 'review'].values\n",
        "y_test = df.loc[17500:, 'sentiment'].values"
      ],
      "metadata": {
        "id": "fNCx2M1JqiCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working on Texts"
      ],
      "metadata": {
        "id": "_5IsS7ZcqijE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장들을 토큰으로 나누기\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split() # 공백을 기준으로 나누기\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()] # 어간추출방법을 이용"
      ],
      "metadata": {
        "id": "N8pnZ6Koqkac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 공백기준 토큰나누기 예시\n",
        "tokenizer(\"runners like running and thus they run\")"
      ],
      "metadata": {
        "id": "odlJxlc-qmft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 어간추출기준 토큰나누기 예시\n",
        "tokenizer_porter(\"runners like running and thus they run\")"
      ],
      "metadata": {
        "id": "8pBtZh8uqm-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 집합을 불러오기\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "id": "2yP0tHg_qoLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}